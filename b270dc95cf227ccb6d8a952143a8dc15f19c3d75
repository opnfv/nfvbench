{
  "comments": [
    {
      "key": {
        "uuid": "9a561d44_d94d8f74",
        "filename": "nfvbench/chain_clients.py",
        "patchSetId": 1
      },
      "lineNbr": 629,
      "author": {
        "id": 5807
      },
      "writtenOn": "2018-08-11T15:35:39Z",
      "side": 1,
      "message": "ok you assume nova will place the second vm on another host - if load balancing allows it. So there is just one case where inter-node could have been satisfied when load balancing is not favorable (e.g. node A has 0 VM, node B has 1 VM, running PVVP inter-node will place the second VM on A even though it should have been B)\n\nThe only good way to handle this properly is to use node anti-affinity for the second VM.\n\nBut since this code is being rewritten we\u0027ll just make it simple here an dhave a small caveat.",
      "revId": "b270dc95cf227ccb6d8a952143a8dc15f19c3d75",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a561d44_f981734b",
        "filename": "nfvbench/chain_clients.py",
        "patchSetId": 1
      },
      "lineNbr": 629,
      "author": {
        "id": 6909
      },
      "writtenOn": "2018-08-11T17:56:35Z",
      "side": 1,
      "message": "Yeah, it still won\u0027t work if there is existing VMs running. But how do we want to handle anti-affinity? We won\u0027t know where VM is placed up in front, unless it runs through the scheduler and becomes active. Also from API perspective, there is no way you can specify a list of AZs (hypervisors) for VMs to use, unless you create a new host aggregate or AZ, will it be too complicated?",
      "parentUuid": "9a561d44_d94d8f74",
      "revId": "b270dc95cf227ccb6d8a952143a8dc15f19c3d75",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a561d44_396f6b94",
        "filename": "nfvbench/chain_clients.py",
        "patchSetId": 1
      },
      "lineNbr": 629,
      "author": {
        "id": 5807
      },
      "writtenOn": "2018-08-12T14:55:08Z",
      "side": 1,
      "message": "the simplest we can do fpr PVVP inter is as follows:\n- create first VM1 as it does now (let nova pick)\n- create anti-affinity rule for VM1\n- create second VM VM2 and let nova pick but with the anti-affinity rule - if it fails, abort the run \n- then for subsequent chains, follow the same placement as first chain\nThis will work in most cases and can fail if nova picks a host that does not have enough resources for subsequent chains - in that case it is ok to abort the run.",
      "parentUuid": "9a561d44_f981734b",
      "revId": "b270dc95cf227ccb6d8a952143a8dc15f19c3d75",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    }
  ]
}